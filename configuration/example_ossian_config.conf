

[DEFAULT]

TOPLEVEL: /Users/owatts/simple4all/dnn_tts

[Paths]

# where to place work files
work: %(TOPLEVEL)s/experiments/test

# where to find the data
data: %(TOPLEVEL)s/data

# list of file basenames, training and validation in a single list
file_id_list: %(data)s/file_id_list.scp.22

in_mgc_dir: %(data)s/mcep
in_bap_dir: %(data)s/bndap
in_lf0_dir: %(data)s/lf0

in_step_dir: %(data)s/step  ### osw added this -- no default set

# where to save plots
plot: %(work)s/log

# logging
log_config_file: %(TOPLEVEL)s/configs/logging_config.conf
log_file: %(work)s/log/mylogfilename.log


## osw added
sptk: /Users/owatts/repos/ossian_git_gold/Ossian/tools/bin
straight: /Users/owatts/repos/STRAIGHT-FFT-Synthesis/bin
# nndata: /Users/owatts/repos/dnn_tts/tools/NeuralNetworkData/bin

[Extensions]

mgc_ext: .mcep
bap_ext: .bndap



[Labels]

process_labels_in_work_dir: True

# There are currently two supported options
#  can only use one of these at a time
#  this stuff will become more flexible and powerful over time

# 1. only HTS labels, with time alignments, plus corresponding questions file
# These are still needed when preparing CMP files, even if using pure Ossian labels later
# that is because currently silence trimming is only implemented from HTS labels
#  this is a little messy and means the complete pipeline cannot be run with 'composed' style labels
#  therefore, we still need to improve this part of the code
#  
# data:  /Users/owatts/simple4all/dnn_tts/data
# label_style: HTS
# label_align: %(data)s/label_state_align
# question_file_name: %(data)s/questions_dnn.hed

# new label preprocesser, which can compile labels from multiple sources
# 
label_style: composed
xpath_label_align: %(TOPLEVEL)s/data/utt_01
fill_missing_values: False
label_config: %(TOPLEVEL)s/configs/label_config_001.py
remove_silence_using_binary_labels: True
precompile_xpaths: True
iterate_over_frames: True

[Utility]
# global control over whether any plots are produced
plot    : True
# global switch to turn code profiling on or off
#  still to implement - fine-grained control over which modules to profile ?
profile : True


[Architecture]
output_layer_activation: linear
hidden_layers_sizes: [256, 256, 256, 256, 256, 256]
learning_rate    : 0.01
L1_regularization: 0.0
L2_regularization: 0.00001
batch_size       : 16
hidden_activation: tanh
output_activation: linear


# [Outputs]
# mgc: 50
# dmgc : 150


[Streams]
# which features to be used in the output
#  could move this to its own config file, just like for the input labels
output_features      : ['mgc', 'lf0', 'vuv', 'bap']


## zhizheng: 2400 70 72
[Data]
train_file_number: 20
valid_file_number: 1
test_file_number : 1
utterance_buffer_size: 400


[Processes]
NORMLAB  : False
MAKECMP  : False
NORMCMP  : False
TRAINDNN : False
DNNGEN   : False
GENWAV   : False
CALMCD   : True

